---
layout: post
author: mrrobot
title: 使用python脚本爬取自己博客的博文
---

>最近在学习python和爬虫的知识，写了一个很简单的脚本来下载本博客所有的博文，文件存放问html文件。

直接上代码：

```
#-*- coding:utf-8 -*-
import requests
import re
from bs4 import BeautifulSoup 
import os
import sys
reload(sys)
sys.setdefaultencoding( "utf-8" )

#爬自己的博客的博文

class Mrrobot:

	def __init__(self):
		#存放文章标题，用于生成文章url
		self.baseUrl='http://mrrobot97.me'
		self.url='http://mrrobot97.me'
		self.titles=[]
		self.dirName='posts'


	def getPageContent(self,url):
		response=None
		response=requests.get(url)
		return response.text

	def getTitles(self):
		content=self.getPageContent(self.url)
		soup=BeautifulSoup(content)
		for h in soup.find_all('h1'):
			path=re.sub(' ','-',str(h.string).strip())
			self.titles.append(path)
		self.savePostsToHtml()
		#获取下一页的链接
		pattern=re.compile('<h2>.*?<a href="(.*?)".*?- more posts -',re.S)
		nextPage=re.findall(pattern,content)
		if nextPage:
			self.url='http://mrrobot97.me'+str(nextPage[0])
			self.start()

	def savePostsToHtml(self):
		if not os.path.exists(self.dirName):
			os.makedirs(self.dirName)
		for title in self.titles:
			if not title=='None':
				url=self.baseUrl+'/'+title
				print u'正在下载网页'+url+'     的源文件'
				content=self.getPageContent(url)
				file=open(self.dirName+'/'+title+'.html','w+')
				file.write(content.encode('utf-8'))
			print u'网页内容爬取完成'
		self.titles=[]

	def start(self):
		self.getTitles()

mrrobot=Mrrobot()
mrrobot.start()
```